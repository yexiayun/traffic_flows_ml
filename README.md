## 交通流预测


## 笔记
### Sequence

在应用机器学习中，我们经常处理集合，例如一列或一组样本的测试集。集合中的每个样本都可以看作是定义域中的一个观察值。在一个集合中，观察的顺序并不重要。

序列是不同的。**序列对观测结果施加了明确的顺序。顺序很重要。在使用序列数据作为模型的输入或输出的预测问题的制定过程中，必须考虑到这一点**。

### 反向传播

反向传播训练算法的目标是修改神经网络的权值，使网络输出相对于相应输入的期望输出的误差最小化。它是一种监督学习算法，允许网络根据特定的错误进行纠正。一般算法如下:

- 提供一个训练输入模式，并通过网络传播它以获得输出。
- 将预测输出与预期输出进行比较，并计算误差。
- 计算误差对网络权值的导数。
- 调整权重以使误差最小化。
- 重复。

### 模型选择、欠拟合和过拟合
将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting）， 用于对抗过拟合的技术称为正则化（regularization）。 在前面的章节中，你可能在用Fashion-MNIST数据集做实验时已经观察到了这种过拟合现象。 在实验中调整模型架构或超参数时，你会发现： 如果有足够多的神经元、层数和训练迭代周期， 模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降了。

在本节中，为了给你一些直观的印象，我们将重点介绍几个倾向于影响模型泛化的因素：

1、可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。

2、参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。

3、训练样本的数量。即使你的模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。

### 欠拟合还是过拟合？

当我们比较训练和验证误差时，我们要注意两种常见的情况。 首先，我们要注意这样的情况：训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足）， 无法捕获试图学习的模式。 此外，由于我们的训练和验证误差之间的泛化误差很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为欠拟合（underfitting）。

另一方面，当我们的训练误差明显低于验证误差时要小心， 这表明严重的过拟合（overfitting）。 注意，过拟合并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。

### 数据集大小

另一个重要因素是数据集的大小。 训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合。 随着训练数据量的增加，泛化误差通常会减小。 此外，一般来说，更多的数据不会有什么坏处。 对于固定的任务和数据分布，模型复杂性和数据集大小之间通常存在关系。 给出更多的数据，我们可能会尝试拟合一个更复杂的模型。 能够拟合更复杂的模型可能是有益的。 如果没有足够的数据，简单的模型可能更有用。 对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型。 从一定程度上来说，深度学习目前的生机要归功于 廉价存储、互联设备以及数字化经济带来的海量数据集。

### 如何使用验证集

验证集可以用在训练的过程中，一般在训练时，几个epoch结束后跑一次验证集看看效果。(验证得太频繁会影响训练速度)这样做的第一个好处是，可以及时发现模型或者参数的问题，比如模型在验证集上发散啦、出现很奇怪的结果啦(如无穷大)、mAP不增长或者增长很慢啦等等情况，这时可以及时终止训练，重新调参或者调整模型，而不需要等到训练结束。另外一个好处是验证模型的泛化能力，如果在验证集上的效果比训练集上差很多，就该考虑模型是否过拟合了。同时，还可以通过验证集对比不同的模型。

### pytorch的「动态图」与「自动微分」技术

链接：https://zhuanlan.zhihu.com/p/351687500

### 比较完整成熟的深度学习参考项目
- https://github.com/chnsh/DCRNN_PyTorch
- https://github.com/wdzhong/ASTGCN-PyTorch

### VSCode & Anaconda 配置
https://www.youtube.com/watch?v=0Hhqf8L-b_0

### 李宏毅2021春季教程
- 视频课程质量高，注重实践部分
- 作业代码质量高，有参考性
https://github.com/Fafa-DL/Lhy_Machine_Learning
